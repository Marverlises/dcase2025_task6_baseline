## 📁 项目结构与文件说明

### 1. **核心模型文件**

#### `d25_t6/retrieval_module.py` - 核心检索模型
这是项目的核心模型，实现了一个双编码器（Dual-Encoder）的音频检索系统：

**关键组件：**
- **音频编码器**: 使用 PaSST (Patch out Fast Spectrogram Transformer) 编码音频
  - 输入：32kHz采样率的音频
  - 输出：768维特征
  - 通过线性投影层映射到1024维
  
- **文本编码器**: 使用 RoBERTa-large 编码文本查询
  - 处理文本查询（去除标点、小写化）
  - 提取 [CLS] token (第一个token) 作为句子表征
  - 通过线性投影层映射到1024维

- **温度参数**: `tau` - 可训练或固定的温度参数，用于缩放相似度
  
**训练流程：**
- 使用对比学习（Contrastive Learning）训练
- 计算音频-文本对的余弦相似度矩阵
- 损失函数：双向交叉熵损失（音频→文本 和 文本→音频）
- 支持同一音频的多个描述（通过dataset+subset+fname的hash判断相同音频）

**评估指标：**
- mAP@10/16（主要评估指标）
- Recall@1, R@5, R@10
- 支持多个正样本的评估

#### `d25_t6/passt.py` - PaSST音频编码器封装
**PaSSTSNoOverlapWrapper类：**
- 封装了预训练的PaSST模型
- Mel频谱图提取：128个mel bins，32kHz采样率
- 使用patch dropout (patchout) 减少计算量

**CutInputIntoSegmentsWrapper类：**
- 处理长音频的分段策略
- 最大输入长度：10秒 × 32000 = 320,000 samples
- 如果音频超过10秒，分成多个10秒的片段
- 每个片段独立编码后再聚合

### 2. **训练与预测文件**

#### `d25_t6/train.py` - 训练主程序
**功能：**
- 数据集加载：支持 Clotho、AudioCaps、WavCaps
- 训练/验证/测试流程
- 使用 PyTorch Lightning 框架
- Weights & Biases (wandb) 日志记录
- 模型检点保存（监控 val/mAP@10）

**训练配置：**
- 默认20个epoch
- 混合精度训练 (16-bit)
- 学习率调度：warmup + cosine decay
- 支持模型编译（torch.compile）加速

#### `d25_t6/predict.py` - 推理预测
**功能：**
- 加载训练好的checkpoint
- 对音频文件和查询进行编码
- 计算相似度矩阵
- 输出CSV格式的预测结果

### 3. **数据集处理文件**

#### `d25_t6/datasets/audio_loading.py` - 音频加载
**核心功能：**
- 使用 ffmpeg 高效加载音频片段（避免加载完整文件）
- 随机采样30秒片段（如果音频>30秒）
- 填充或截断到固定长度（30秒 × 32000 = 960,000 samples）
- 重采样到32kHz
- 支持mp3和wav格式（WavCaps使用mp3节省空间）

#### `d25_t6/datasets/batch_collate.py` - 批次整理
**CustomCollate类：**
- 将list of dicts转换为dict of lists
- 自动stack相同shape的tensor
- 处理不同类型的数据（tensor vs 普通值）

#### `d25_t6/datasets/download_datasets.py` - 数据集下载
**支持的数据集：**
- **ClothoV2.1**: 开发/验证/评估集
- **AudioCaps**: 从云端下载预处理版本
- **WavCaps**: 
  - 提供mp3压缩版本（15个分卷，节省空间）
  - 包含4个子集：FreeSound, BBC, SoundBible, AudioSet

#### `d25_t6/datasets/utils.py` - 数据集工具
**功能：**
- 检测损坏的音频文件（使用ffmpeg probe）
- 排除禁用文件（与ClothoV2评估集重叠的文件）
- 排除过长的音频文件（>120秒）

### 4. **辅助文件**

#### `scripts/convert_flac_to_mp3.py`
- 将WavCaps从FLAC格式转换为MP3
- 节省磁盘空间：从1.5TB降至150GB
- 使用多线程并行转换

#### `requirements.txt`
主要依赖：
- PyTorch + Lightning
- Transformers (Hugging Face)
- hear21passt (PaSST模型)
- aac-datasets (数据集加载)
- wandb (实验跟踪)

## 🏗️ 整体模型架构

```
输入层
├── 音频分支 (Audio Branch)
│   ├── 音频输入 (32kHz, 最长30秒)
│   ├── Mel频谱图提取 (128 mel bins)
│   ├── PaSST编码器 (Transformer)
│   │   └── 输出: 768维向量
│   ├── 线性投影层 (768 → 1024)
│   └── L2归一化
│
└── 文本分支 (Text Branch)
    ├── 文本查询输入
    ├── 文本预处理 (小写、去标点)
    ├── RoBERTa Tokenizer (最长32 tokens)
    ├── RoBERTa-large编码器
    │   └── 提取[CLS] token: 1024维向量
    ├── 线性投影层 (1024 → 1024)
    └── L2归一化

相似度计算
├── 余弦相似度矩阵: C = audio_emb @ text_emb.T
├── 温度缩放: C = C / |tau|
└── 对比学习损失: -0.5 * (log_softmax(C, dim=0) + log_softmax(C, dim=1))

检索
└── 对于查询文本，返回相似度最高的K个音频
```

## 🎯 核心设计思想

1. **双编码器架构（Dual-Encoder）**: 音频和文本分别编码到共享的1024维语义空间

2. **对比学习（Contrastive Learning）**: 
   - 匹配的音频-文本对应该相似度高
   - 不匹配的对应该相似度低
   - 使用批次内的负样本进行对比

3. **长音频处理**:
   - 分段编码（10秒片段）
   - 根据时长动态聚合：≤10秒用第1段，≤20秒用前2段平均，>20秒全部平均

4. **高效训练**:
   - 使用ffmpeg直接提取音频片段，避免加载完整文件
   - 混合精度训练
   - torch.compile加速（GPU compute capability ≥ 7.0）
   - 学习率warmup + cosine decay

5. **数据集策略**:
   - 基础：ClothoV2（高质量人工标注）
   - 扩展：AudioCaps（YouTube音频）
   - 大规模：WavCaps（40万+音频，弱标注）

